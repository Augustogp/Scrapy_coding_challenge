# Scrapy_coding_challenge

## Assignment 1: Basic Spider and Deploy in Scrapy Cloud

The task is to build a spider to extract the following fields from all the 1000 books available in the website: books.toscrape.com:
Fields to extract: book title, book price, book image URL, book details page URL

### Constraints:

1. Your spider should visit all the categories pages and all the information should be
extracted from those.
2. Your spider should not visit the individual book pages. This way, you'll save a
considerable bandwidth.
3. Use of plugins and custom pipelines is optional. (bonus points)
### Deliverables:

Please provide the following two files in a github or bitbucket repo, and share the link:
a) Code of the spider
b) CSV or XML or JSON file of the four fields for the 1000 books
c) Link to the project deployed in Scrapy Cloud in Zyte Dashboard

## Assignment 2: Spider with Javascript

Scrape and extract quote, author and tags from http://quotes.toscrape.com/js/ You would need to use your choice of Headless browser or Splash to be able to execute the javascript. No need to deploy this spider on Scrapy Cloud.

### Deliverables:

Please provide the github or bitbucket link to the code of the spider and extracted data: quote,
author, and tags (in any format)